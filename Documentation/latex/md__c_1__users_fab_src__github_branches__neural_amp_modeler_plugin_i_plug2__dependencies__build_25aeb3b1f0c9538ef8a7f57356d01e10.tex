This A\+PI allows to interact with a natively compiled \mbox{\hyperlink{struct_faust}{Faust}} object and its associated audio engine at a very high level from the J\+A\+VA layer of an Android app. The idea is that all the audio part of the app is implemented in \mbox{\hyperlink{struct_faust}{Faust}} allowing developers to focus on the design of the app itself.

For more details on how to create Android apps from scratch using this tool, check the \href{https://ccrma.stanford.edu/~rmichon/faust2api}{\texttt{ {\ttfamily faust2api} documentation}} or the \href{https://ccrma.stanford.edu/~rmichon/faustTutorials/\#adding-faust-real-time-audio-support-to-android-apps}{\texttt{ {\itshape Adding Faust Real-\/\+Time Audio Support to Android Apps Tutorial}}}.\hypertarget{md__c_1__users_fab_src__github_branches__neural_amp_modeler_plugin_i_plug2__dependencies__build_25aeb3b1f0c9538ef8a7f57356d01e10_autotoc_md860}{}\doxysection{Using This Package}\label{md__c_1__users_fab_src__github_branches__neural_amp_modeler_plugin_i_plug2__dependencies__build_25aeb3b1f0c9538ef8a7f57356d01e10_autotoc_md860}
This section is an accelerated version of the \href{https://ccrma.stanford.edu/~rmichon/faustTutorials/\#adding-faust-real-time-audio-support-to-android-apps}{\texttt{ {\itshape Adding Faust Real-\/\+Time Audio Support to Android Apps Tutorial}}}. We strongly recommend you to read it if this is the first time that you use this tool or if you never used the Android N\+DK (Native Development Kit).\hypertarget{md__c_1__users_fab_src__github_branches__neural_amp_modeler_plugin_i_plug2__dependencies__build_25aeb3b1f0c9538ef8a7f57356d01e10_autotoc_md861}{}\doxysubsection{App Set-\/\+Up}\label{md__c_1__users_fab_src__github_branches__neural_amp_modeler_plugin_i_plug2__dependencies__build_25aeb3b1f0c9538ef8a7f57356d01e10_autotoc_md861}
Very little work has to be done to integrate this package to your Android app. Once this is done, you will be able to interact with the \mbox{\hyperlink{struct_faust}{Faust}} \mbox{\hyperlink{class_d_s_p}{D\+SP}} module from J\+A\+VA without having to write a line of native C++ code.

This package contains 2 folder\+: {\ttfamily /cpp} and {\ttfamily /java}. {\ttfamily cpp} hosts the native C++ elements that should be placed in the N\+DK folder of your app. {\ttfamily /java} contains the J\+A\+VA classes that should be placed in the {\ttfamily java} folder of your app in accordance with the J\+A\+VA package that was configured when {\ttfamily faust2api} was ran. The default package name is {\ttfamily com.\+Dsp\+Faust}, thus, in that case, the content of {\ttfamily /java} should be placed in {\ttfamily java/com/\+Dsp\+Faust}. You can check the \href{https://ccrma.stanford.edu/~rmichon/faust2api/}{\texttt{ faust2api documentation}} to get more information about that.

In order for things to compile, your Gradle file should have an {\ttfamily external\+Native\+Build} with something like that in it\+:


\begin{DoxyCode}{0}
\DoxyCodeLine{externalNativeBuild \{}
\DoxyCodeLine{    cmake \{}
\DoxyCodeLine{        cppFlags "-\/O3 -\/fexceptions -\/frtti -\/lOpenSLES"}
\DoxyCodeLine{    \}}
\DoxyCodeLine{\}}
\end{DoxyCode}


Also, the N\+DK C\+Make file should look like this\+:


\begin{DoxyCode}{0}
\DoxyCodeLine{cmake\_minimum\_required(VERSION 3.4.1)}
\DoxyCodeLine{add\_library( }
\DoxyCodeLine{    dsp\_faust }
\DoxyCodeLine{    SHARED }
\DoxyCodeLine{    src/main/cpp/java\_interface\_wrap.cpp }
\DoxyCodeLine{    src/main/cpp/DspFaust.cpp }
\DoxyCodeLine{)}
\DoxyCodeLine{find\_library( log-\/lib log )}
\DoxyCodeLine{target\_link\_libraries( dsp\_faust \$\{log-\/lib\} )}
\end{DoxyCode}


Finally, since your \mbox{\hyperlink{struct_faust}{Faust}} object might need to access the audio input of your device, the following line should be added to the manifest of your app (typically before the {\ttfamily application} tag)\+: \begin{DoxyVerb}<uses-permission android:name="android.permission.RECORD_AUDIO"/>
\end{DoxyVerb}


After this, re-\/synchronize Gradle and try to compile the Android app. Hopefully, things should go well!\hypertarget{md__c_1__users_fab_src__github_branches__neural_amp_modeler_plugin_i_plug2__dependencies__build_25aeb3b1f0c9538ef8a7f57356d01e10_autotoc_md862}{}\doxysubsection{Using the J\+A\+V\+A A\+PI}\label{md__c_1__users_fab_src__github_branches__neural_amp_modeler_plugin_i_plug2__dependencies__build_25aeb3b1f0c9538ef8a7f57356d01e10_autotoc_md862}
The \mbox{\hyperlink{struct_faust}{Faust}} J\+A\+VA A\+PI is designed to seamlessly integrate to the life cycle of an Android app. It is accessible through a single {\ttfamily \mbox{\hyperlink{class_dsp_faust}{Dsp\+Faust}}} object. The constructor of that object is used to set the sampling rate and the block size\+: \begin{DoxyVerb}DspFaust dspFaust = new DspFaust(SR, blockSize);
\end{DoxyVerb}


The {\ttfamily start()} method is used to start the audio computing and would typically be placed in the {\ttfamily on\+Create()} method of the app activity.

Similarly, {\ttfamily stop()} can be called to stop the audio computing and can be placed in {\ttfamily on\+Detroy()}, etc.

Garbage collection on the native side is taken care of so you don\textquotesingle{}t have to worry about it.

It is possible to interact with the different parameters of the \mbox{\hyperlink{struct_faust}{Faust}} object by using the {\ttfamily set\+Param\+Value} method. Two versions of this method exist\+: one where the parameter can be selected by its address and one where it can be selected using its ID. The \href{\#parameters-list}{\texttt{ Parameters List}} section gives a list of the addresses and corresponding I\+Ds of the current \mbox{\hyperlink{struct_faust}{Faust}} object.

If your \mbox{\hyperlink{struct_faust}{Faust}} object is polyphonic (e.\+g. if you used the {\ttfamily -\/nvoices} option when generating this A\+PI), then you can use the M\+I\+DI polyphony methods like {\ttfamily key\+On}, {\ttfamily key\+Off}, etc.

It is possible to change the parameters of polyphonic voices independently using the {\ttfamily set\+Voice\+Param\+Value} method. This method takes as one of its arguments the address to the voice returned by {\ttfamily key\+On} or {\ttfamily new\+Voice} when it is called. E.\+g\+: \begin{DoxyVerb}long voiceAddress = dspFaust.keyOn(70, 100);
dspFaust.setVoiceParamValue(1, voiceAddress, 214);
dspFaust.keyOff(70);
\end{DoxyVerb}


In the example above, a new note is created and its parameter ID 1 is modified. This note is then terminated. Note that parameters addresses (path) are different for independent voices than when using {\ttfamily set\+Param\+Value}. The list of these addresses is provided in a separate sub-\/section of the \href{\#parameters-list}{\texttt{ Parameters List}} section.

Finally, note that new voices don\textquotesingle{}t necessarily have to be created using {\ttfamily key\+On}. Indeed, you might choose to just use the {\ttfamily new\+Voice} method for that\+: \begin{DoxyVerb}long voiceAddress = dspFaust.newVoice;
dspFaust.setVoiceParamValue(1, voiceAddress, 214);
dspFaust.deleteVoice(voiceAddress);
\end{DoxyVerb}


This is particularly useful when making apps where each finger of the user is an independent sound that doesn\textquotesingle{}t necessarily has a pitch.

In case you would like to use the the built-\/in accelerometer or gyroscope of your device to control some of the parameters of your \mbox{\hyperlink{struct_faust}{Faust}} object, all you have to do is to send the raw accelerometer data to it by using the {\ttfamily propagate\+Acc} or {\ttfamily propagate\+Gyr} for the gyroscope. After that, mappings can be configured directly from the \mbox{\hyperlink{struct_faust}{Faust}} code using \href{\#using-built-in-sensors-to-control-parameters}{\texttt{ this technique}} or using the {\ttfamily set\+Acc\+Converter} and {\ttfamily set\+Gyr\+Converter} method. 