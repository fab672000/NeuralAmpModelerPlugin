This sample demonstrates how to build a simple musical game. The objective of the game is to clap in time to a song by copying what you hear. You do this by listening to the clap sounds, then tapping on the screen to copy those claps.

For a step-\/by-\/step guide on how this game works and how to build it check out this codelab\+: \href{https://codelabs.developers.google.com/codelabs/musicalgame-using-oboe/index.html}{\texttt{ Build a Musical Game using Oboe}}.\hypertarget{md__c_1__users_fab_src__github_branches__neural_amp_modeler_plugin_i_plug2__dependencies__build_874158d6837623bc8c4b4c1de6ac7afd_autotoc_md184}{}\doxysection{Screenshots}\label{md__c_1__users_fab_src__github_branches__neural_amp_modeler_plugin_i_plug2__dependencies__build_874158d6837623bc8c4b4c1de6ac7afd_autotoc_md184}
The \mbox{\hyperlink{class_u_i}{UI}} is deliberately very simple -\/ just tap anywhere in the grey area after hearing the claps. The \mbox{\hyperlink{class_u_i}{UI}} will change color to indicate the game state. The colors are\+:


\begin{DoxyItemize}
\item Yellow\+: \mbox{\hyperlink{class_game}{Game}} is loading (assets are being decompressed)
\item Grey\+: \mbox{\hyperlink{class_game}{Game}} is being played
\item Orange\+: You tapped too early
\item Green\+: You tapped on time
\item Purple\+: You tapped too late
\item Red\+: There was a problem loading the game (check logcat output)
\end{DoxyItemize}

\hypertarget{md__c_1__users_fab_src__github_branches__neural_amp_modeler_plugin_i_plug2__dependencies__build_874158d6837623bc8c4b4c1de6ac7afd_autotoc_md185}{}\doxysubsection{Audio timeline}\label{md__c_1__users_fab_src__github_branches__neural_amp_modeler_plugin_i_plug2__dependencies__build_874158d6837623bc8c4b4c1de6ac7afd_autotoc_md185}


The game plays the clap sounds on the first 3 beats of the bar. These are played in time with the backing track.

When the user taps on the screen, a clap sound is played and the game checks whether the tap occurred within an acceptable time window.\hypertarget{md__c_1__users_fab_src__github_branches__neural_amp_modeler_plugin_i_plug2__dependencies__build_874158d6837623bc8c4b4c1de6ac7afd_autotoc_md186}{}\doxysubsection{Architecture}\label{md__c_1__users_fab_src__github_branches__neural_amp_modeler_plugin_i_plug2__dependencies__build_874158d6837623bc8c4b4c1de6ac7afd_autotoc_md186}


Oboe provides the \href{https://github.com/google/oboe/blob/master/include/oboe/AudioStream.h}{\texttt{ {\ttfamily Audio\+Stream}}} class and associated objects to allow the sample to output audio data to the audio device. All other objects are provided by the sample.

Each time the {\ttfamily Audio\+Stream} needs more audio data it calls \href{https://github.com/google/oboe/blob/master/include/oboe/AudioStreamCallback.h}{\texttt{ {\ttfamily Audio\+Data\+Callback\+::on\+Audio\+Ready}}}. This passes a container array named {\ttfamily audio\+Data} to the {\ttfamily \mbox{\hyperlink{class_game}{Game}}} object which must then fill the array with {\ttfamily num\+Frames} of audio frames.

\hypertarget{md__c_1__users_fab_src__github_branches__neural_amp_modeler_plugin_i_plug2__dependencies__build_874158d6837623bc8c4b4c1de6ac7afd_autotoc_md187}{}\doxysubsection{Latency optimizations}\label{md__c_1__users_fab_src__github_branches__neural_amp_modeler_plugin_i_plug2__dependencies__build_874158d6837623bc8c4b4c1de6ac7afd_autotoc_md187}
The sample uses the following optimizations to obtain a low latency audio stream\+:


\begin{DoxyItemize}
\item Performance mode set to \href{https://github.com/google/oboe/blob/master/FullGuide.md\#setting-performance-mode}{\texttt{ Low Latency}}
\item Sharing mode set to \href{https://github.com/google/oboe/blob/master/FullGuide.md\#sharing-mode}{\texttt{ Exclusive}}
\item \mbox{\hyperlink{class_buffer}{Buffer}} size set to twice the number of frames in a burst (double buffering)
\end{DoxyItemize}\hypertarget{md__c_1__users_fab_src__github_branches__neural_amp_modeler_plugin_i_plug2__dependencies__build_874158d6837623bc8c4b4c1de6ac7afd_autotoc_md188}{}\doxysubsection{Audio rendering}\label{md__c_1__users_fab_src__github_branches__neural_amp_modeler_plugin_i_plug2__dependencies__build_874158d6837623bc8c4b4c1de6ac7afd_autotoc_md188}
The {\ttfamily \mbox{\hyperlink{class_i_renderable_audio}{I\+Renderable\+Audio}}} interface (abstract class) represents objects which can produce frames of audio data. The {\ttfamily \mbox{\hyperlink{class_player}{Player}}} and {\ttfamily \mbox{\hyperlink{class_mixer}{Mixer}}} objects both implement this interface.

Both the clap sound and backing tracks are represented by {\ttfamily \mbox{\hyperlink{class_player}{Player}}} objects which are then mixed together using a {\ttfamily \mbox{\hyperlink{class_mixer}{Mixer}}}.

\hypertarget{md__c_1__users_fab_src__github_branches__neural_amp_modeler_plugin_i_plug2__dependencies__build_874158d6837623bc8c4b4c1de6ac7afd_autotoc_md189}{}\doxysubsection{Sharing objects with the audio thread}\label{md__c_1__users_fab_src__github_branches__neural_amp_modeler_plugin_i_plug2__dependencies__build_874158d6837623bc8c4b4c1de6ac7afd_autotoc_md189}
It is very important that the audio thread (which calls the {\ttfamily on\+Audio\+Ready} method) is never blocked. Blocking can cause underruns and audio glitches. To avoid blocking we use a {\ttfamily \mbox{\hyperlink{class_lock_free_queue}{Lock\+Free\+Queue}}} to share information between the audio thread and other threads. The following diagram shows how claps are enqueued by pushing the clap times (in milliseconds) onto the queue, then dequeuing the clap time when the clap is played.



We also use \href{http://en.cppreference.com/w/cpp/atomic/atomic}{\texttt{ atomics}} to ensure that threads see a consistent view of any shared primitives.\hypertarget{md__c_1__users_fab_src__github_branches__neural_amp_modeler_plugin_i_plug2__dependencies__build_874158d6837623bc8c4b4c1de6ac7afd_autotoc_md190}{}\doxysubsection{Keeping U\+I events and audio in sync}\label{md__c_1__users_fab_src__github_branches__neural_amp_modeler_plugin_i_plug2__dependencies__build_874158d6837623bc8c4b4c1de6ac7afd_autotoc_md190}
When a tap event arrives on the \mbox{\hyperlink{class_u_i}{UI}} thread it only contains the time (milliseconds since boot) that the event occurred. We need to figure out what the song position was when the tap occurred.

To do this we keep track of the song position and the time it was last updated. These values are updated each time the {\ttfamily on\+Audio\+Ready} method is called. This enables us to keep the \mbox{\hyperlink{class_u_i}{UI}} in sync with the audio timeline.

\hypertarget{md__c_1__users_fab_src__github_branches__neural_amp_modeler_plugin_i_plug2__dependencies__build_874158d6837623bc8c4b4c1de6ac7afd_autotoc_md191}{}\doxysubsection{Calculating whether a tap was successful}\label{md__c_1__users_fab_src__github_branches__neural_amp_modeler_plugin_i_plug2__dependencies__build_874158d6837623bc8c4b4c1de6ac7afd_autotoc_md191}
Once we know when the user tapped in the song, we can calculate whether that tap was successful i.\+e whether it fell within an acceptable time range. This range is known as the \char`\"{}tap window\char`\"{}.



Once we know the result of the tap the \mbox{\hyperlink{class_u_i}{UI}} is updated with a color to give the user visual feedback. This is done in {\ttfamily get\+Tap\+Result}.

Note that once a tap has been received the tap window is removed from the queue -\/ the user only gets one chance to get their tap right!\hypertarget{md__c_1__users_fab_src__github_branches__neural_amp_modeler_plugin_i_plug2__dependencies__build_874158d6837623bc8c4b4c1de6ac7afd_autotoc_md192}{}\doxysubsection{Use of compressed audio assets}\label{md__c_1__users_fab_src__github_branches__neural_amp_modeler_plugin_i_plug2__dependencies__build_874158d6837623bc8c4b4c1de6ac7afd_autotoc_md192}
In order to reduce A\+PK size this game uses M\+P3 files for its audio assets. These are extracted on game startup in {\ttfamily A\+Asset\+Data\+Source\+::new\+From\+Compressed\+Asset}. A yellow screen will be shown during this process.

By default the game uses {\ttfamily \mbox{\hyperlink{class_n_d_k_extractor}{N\+D\+K\+Extractor}}} for asset extraction and decoding. Under the hood this uses the \href{https://developer.android.com/ndk/reference/group/media}{\texttt{ N\+DK Media A\+P\+Is}}.

There are some limitations with this approach\+:


\begin{DoxyItemize}
\item Only available on A\+PI 21 and above
\item No resampling\+: The extracted output format will match the input format of the M\+P3. In this case a sample rate of 48000. If your audio stream\textquotesingle{}s sample rate doesn\textquotesingle{}t match the assets will not be extracted and an error will be displayed in logcat.
\item 16-\/bit output only.
\end{DoxyItemize}

A faster, more versatile solution is to use \href{https://www.ffmpeg.org/}{\texttt{ F\+Fmpeg}}. To do this follow \href{https://medium.com/@donturner/using-ffmpeg-for-faster-audio-decoding-967894e94e71}{\texttt{ the instructions here}} and use the {\ttfamily ffmpeg\+Extractor} build variant found in {\ttfamily app.\+gradle}. The extraction will then be done by {\ttfamily F\+Fmpeg\+Extractor}. 