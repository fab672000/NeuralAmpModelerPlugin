\hypertarget{class_eigen_1_1_conjugate_gradient}{}\doxysection{Eigen\+::Conjugate\+Gradient$<$ Matrix\+Type\+\_\+, Up\+Lo\+\_\+, Preconditioner\+\_\+ $>$ Class Template Reference}
\label{class_eigen_1_1_conjugate_gradient}\index{Eigen::ConjugateGradient$<$ MatrixType\_, UpLo\_, Preconditioner\_ $>$@{Eigen::ConjugateGradient$<$ MatrixType\_, UpLo\_, Preconditioner\_ $>$}}


A conjugate gradient solver for sparse (or dense) self-\/adjoint problems.  




{\ttfamily \#include $<$Conjugate\+Gradient.\+h$>$}

\doxysubsection*{Public Types}
\begin{DoxyCompactItemize}
\item 
\mbox{\Hypertarget{class_eigen_1_1_conjugate_gradient_ab662f0ecac1fc829c93fa4cf338176e2}\label{class_eigen_1_1_conjugate_gradient_ab662f0ecac1fc829c93fa4cf338176e2}} 
enum \{ {\bfseries Up\+Lo} = Up\+Lo\+\_\+
 \}
\item 
\mbox{\Hypertarget{class_eigen_1_1_conjugate_gradient_a292af147e3097bf4407275ae28b6358f}\label{class_eigen_1_1_conjugate_gradient_a292af147e3097bf4407275ae28b6358f}} 
enum \{ {\bfseries Up\+Lo} = Up\+Lo\+\_\+
 \}
\item 
\mbox{\Hypertarget{class_eigen_1_1_conjugate_gradient_ade3343d2917dfdb4e9c24f6894608d6c}\label{class_eigen_1_1_conjugate_gradient_ade3343d2917dfdb4e9c24f6894608d6c}} 
typedef Matrix\+Type\+\_\+ {\bfseries Matrix\+Type}
\item 
\mbox{\Hypertarget{class_eigen_1_1_conjugate_gradient_a5ccb70fe9fcd70abc91206dd9990e37e}\label{class_eigen_1_1_conjugate_gradient_a5ccb70fe9fcd70abc91206dd9990e37e}} 
typedef Matrix\+Type\+::\+Scalar {\bfseries Scalar}
\item 
\mbox{\Hypertarget{class_eigen_1_1_conjugate_gradient_a8080a0f4db71dc748a925ab108dce550}\label{class_eigen_1_1_conjugate_gradient_a8080a0f4db71dc748a925ab108dce550}} 
typedef Matrix\+Type\+::\+Real\+Scalar {\bfseries Real\+Scalar}
\item 
\mbox{\Hypertarget{class_eigen_1_1_conjugate_gradient_afbc182abcf0df53ec6654eba6278c775}\label{class_eigen_1_1_conjugate_gradient_afbc182abcf0df53ec6654eba6278c775}} 
typedef Preconditioner\+\_\+ {\bfseries Preconditioner}
\item 
\mbox{\Hypertarget{class_eigen_1_1_conjugate_gradient_ade3343d2917dfdb4e9c24f6894608d6c}\label{class_eigen_1_1_conjugate_gradient_ade3343d2917dfdb4e9c24f6894608d6c}} 
typedef Matrix\+Type\+\_\+ {\bfseries Matrix\+Type}
\item 
\mbox{\Hypertarget{class_eigen_1_1_conjugate_gradient_a5ccb70fe9fcd70abc91206dd9990e37e}\label{class_eigen_1_1_conjugate_gradient_a5ccb70fe9fcd70abc91206dd9990e37e}} 
typedef Matrix\+Type\+::\+Scalar {\bfseries Scalar}
\item 
\mbox{\Hypertarget{class_eigen_1_1_conjugate_gradient_a8080a0f4db71dc748a925ab108dce550}\label{class_eigen_1_1_conjugate_gradient_a8080a0f4db71dc748a925ab108dce550}} 
typedef Matrix\+Type\+::\+Real\+Scalar {\bfseries Real\+Scalar}
\item 
\mbox{\Hypertarget{class_eigen_1_1_conjugate_gradient_afbc182abcf0df53ec6654eba6278c775}\label{class_eigen_1_1_conjugate_gradient_afbc182abcf0df53ec6654eba6278c775}} 
typedef Preconditioner\+\_\+ {\bfseries Preconditioner}
\end{DoxyCompactItemize}
\doxysubsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{class_eigen_1_1_conjugate_gradient_aa1082311045904603fdbc9e717d40d24}{Conjugate\+Gradient}} ()
\item 
{\footnotesize template$<$typename Matrix\+Derived $>$ }\\\mbox{\hyperlink{class_eigen_1_1_conjugate_gradient_a81b93cc6401f61e0ff2ff0fc8a959fe3}{Conjugate\+Gradient}} (const \mbox{\hyperlink{struct_eigen_1_1_eigen_base}{Eigen\+Base}}$<$ Matrix\+Derived $>$ \&\mbox{\hyperlink{class_eigen_1_1_matrix}{A}})
\item 
\mbox{\Hypertarget{class_eigen_1_1_conjugate_gradient_ac6a7568152cca3739faedb0a1254f350}\label{class_eigen_1_1_conjugate_gradient_ac6a7568152cca3739faedb0a1254f350}} 
{\footnotesize template$<$typename Rhs , typename Dest $>$ }\\void {\bfseries \+\_\+solve\+\_\+vector\+\_\+with\+\_\+guess\+\_\+impl} (const Rhs \&b, Dest \&x) const
\item 
\mbox{\hyperlink{class_eigen_1_1_conjugate_gradient_aa1082311045904603fdbc9e717d40d24}{Conjugate\+Gradient}} ()
\item 
{\footnotesize template$<$typename Matrix\+Derived $>$ }\\\mbox{\hyperlink{class_eigen_1_1_conjugate_gradient_a81b93cc6401f61e0ff2ff0fc8a959fe3}{Conjugate\+Gradient}} (const \mbox{\hyperlink{struct_eigen_1_1_eigen_base}{Eigen\+Base}}$<$ Matrix\+Derived $>$ \&\mbox{\hyperlink{class_eigen_1_1_matrix}{A}})
\item 
\mbox{\Hypertarget{class_eigen_1_1_conjugate_gradient_ac6a7568152cca3739faedb0a1254f350}\label{class_eigen_1_1_conjugate_gradient_ac6a7568152cca3739faedb0a1254f350}} 
{\footnotesize template$<$typename Rhs , typename Dest $>$ }\\void {\bfseries \+\_\+solve\+\_\+vector\+\_\+with\+\_\+guess\+\_\+impl} (const Rhs \&b, Dest \&x) const
\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
\subsubsection*{template$<$typename Matrix\+Type\+\_\+, int Up\+Lo\+\_\+, typename Preconditioner\+\_\+$>$\newline
class Eigen\+::\+Conjugate\+Gradient$<$ Matrix\+Type\+\_\+, Up\+Lo\+\_\+, Preconditioner\+\_\+ $>$}

A conjugate gradient solver for sparse (or dense) self-\/adjoint problems. 

This class allows to solve for A.\+x = b linear problems using an iterative conjugate gradient algorithm. The matrix A must be selfadjoint. The matrix A and the vectors x and b can be either dense or sparse.


\begin{DoxyTemplParams}{Template Parameters}
{\em Matrix\+Type\+\_\+} & the type of the matrix A, can be a dense or a sparse matrix. \\
\hline
{\em Up\+Lo\+\_\+} & the triangular part that will be used for the computations. It can be Lower, {\ttfamily Upper}, or {\ttfamily Lower$\vert$\+Upper} in which the full matrix entries will be considered. Default is {\ttfamily Lower}, best performance is {\ttfamily Lower$\vert$\+Upper}. \\
\hline
{\em Preconditioner\+\_\+} & the type of the preconditioner. Default is \mbox{\hyperlink{class_eigen_1_1_diagonal_preconditioner}{Diagonal\+Preconditioner}}\\
\hline
\end{DoxyTemplParams}
\textbackslash{}implsparsesolverconcept

The maximal number of iterations and tolerance value can be controlled via the set\+Max\+Iterations() and set\+Tolerance() methods. The defaults are the size of the problem for the maximal number of iterations and \mbox{\hyperlink{group__gtc__constants_ga2a1e57fc5592b69cfae84174cbfc9429}{Num\+Traits$<$\+Scalar$>$\+::epsilon()}} for the tolerance.

The tolerance corresponds to the relative residual error\+: $\vert$\+Ax-\/b$\vert$/$\vert$b$\vert$

{\bfseries{Performance\+:}} Even though the default value of {\ttfamily Up\+Lo\+\_\+} is {\ttfamily Lower}, significantly higher performance is achieved when using a complete matrix and {\bfseries{Lower$\vert$\+Upper}} as the {\itshape Up\+Lo\+\_\+} template parameter. Moreover, in this case multi-\/threading can be exploited if the user code is compiled with Open\+MP enabled. See \mbox{\hyperlink{TopicMultiThreading}{Eigen and multi-\/threading}} for details.

This class can be used as the direct solver classes. Here is a typical usage example\+: 
\begin{DoxyCode}{0}
\DoxyCodeLine{\textcolor{keywordtype}{int} n = 10000;}
\DoxyCodeLine{VectorXd x(n), b(n);}
\DoxyCodeLine{SparseMatrix<double> A(n,n);}
\DoxyCodeLine{\textcolor{comment}{// fill A and b}}
\DoxyCodeLine{ConjugateGradient<SparseMatrix<double>, \mbox{\hyperlink{group__enums_gga39e3366ff5554d731e7dc8bb642f83cda891792b8ed394f7607ab16dd716f60e6}{Lower}}|\mbox{\hyperlink{group__enums_gga39e3366ff5554d731e7dc8bb642f83cda6bcb58be3b8b8ec84859ce0c5ac0aaec}{Upper}}> cg;}
\DoxyCodeLine{cg.compute(A);}
\DoxyCodeLine{x = cg.solve(b);}
\DoxyCodeLine{std::cout << \textcolor{stringliteral}{"\#iterations:     "} << cg.iterations() << std::endl;}
\DoxyCodeLine{std::cout << \textcolor{stringliteral}{"estimated error: "} << cg.error()      << std::endl;}
\DoxyCodeLine{\textcolor{comment}{// update b, and solve again}}
\DoxyCodeLine{x = cg.solve(b);}
\end{DoxyCode}


By default the iterations start with x=0 as an initial guess of the solution. One can control the start using the solve\+With\+Guess() method.

\mbox{\hyperlink{class_eigen_1_1_conjugate_gradient}{Conjugate\+Gradient}} can also be used in a matrix-\/free context, see the following \mbox{\hyperlink{group___matrixfree_solver_example}{example }}.

\begin{DoxySeeAlso}{See also}
class \mbox{\hyperlink{class_eigen_1_1_least_squares_conjugate_gradient}{Least\+Squares\+Conjugate\+Gradient}}, class \mbox{\hyperlink{class_eigen_1_1_simplicial_cholesky}{Simplicial\+Cholesky}}, \mbox{\hyperlink{class_eigen_1_1_diagonal_preconditioner}{Diagonal\+Preconditioner}}, \mbox{\hyperlink{class_eigen_1_1_identity_preconditioner}{Identity\+Preconditioner}} 
\end{DoxySeeAlso}


\doxysubsection{Constructor \& Destructor Documentation}
\mbox{\Hypertarget{class_eigen_1_1_conjugate_gradient_aa1082311045904603fdbc9e717d40d24}\label{class_eigen_1_1_conjugate_gradient_aa1082311045904603fdbc9e717d40d24}} 
\index{Eigen::ConjugateGradient$<$ MatrixType\_, UpLo\_, Preconditioner\_ $>$@{Eigen::ConjugateGradient$<$ MatrixType\_, UpLo\_, Preconditioner\_ $>$}!ConjugateGradient@{ConjugateGradient}}
\index{ConjugateGradient@{ConjugateGradient}!Eigen::ConjugateGradient$<$ MatrixType\_, UpLo\_, Preconditioner\_ $>$@{Eigen::ConjugateGradient$<$ MatrixType\_, UpLo\_, Preconditioner\_ $>$}}
\doxysubsubsection{\texorpdfstring{ConjugateGradient()}{ConjugateGradient()}\hspace{0.1cm}{\footnotesize\ttfamily [1/4]}}
{\footnotesize\ttfamily template$<$typename Matrix\+Type\+\_\+ , int Up\+Lo\+\_\+, typename Preconditioner\+\_\+ $>$ \\
\mbox{\hyperlink{class_eigen_1_1_conjugate_gradient}{Eigen\+::\+Conjugate\+Gradient}}$<$ Matrix\+Type\+\_\+, Up\+Lo\+\_\+, Preconditioner\+\_\+ $>$\+::\mbox{\hyperlink{class_eigen_1_1_conjugate_gradient}{Conjugate\+Gradient}} (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}}

Default constructor. \mbox{\Hypertarget{class_eigen_1_1_conjugate_gradient_a81b93cc6401f61e0ff2ff0fc8a959fe3}\label{class_eigen_1_1_conjugate_gradient_a81b93cc6401f61e0ff2ff0fc8a959fe3}} 
\index{Eigen::ConjugateGradient$<$ MatrixType\_, UpLo\_, Preconditioner\_ $>$@{Eigen::ConjugateGradient$<$ MatrixType\_, UpLo\_, Preconditioner\_ $>$}!ConjugateGradient@{ConjugateGradient}}
\index{ConjugateGradient@{ConjugateGradient}!Eigen::ConjugateGradient$<$ MatrixType\_, UpLo\_, Preconditioner\_ $>$@{Eigen::ConjugateGradient$<$ MatrixType\_, UpLo\_, Preconditioner\_ $>$}}
\doxysubsubsection{\texorpdfstring{ConjugateGradient()}{ConjugateGradient()}\hspace{0.1cm}{\footnotesize\ttfamily [2/4]}}
{\footnotesize\ttfamily template$<$typename Matrix\+Type\+\_\+ , int Up\+Lo\+\_\+, typename Preconditioner\+\_\+ $>$ \\
template$<$typename Matrix\+Derived $>$ \\
\mbox{\hyperlink{class_eigen_1_1_conjugate_gradient}{Eigen\+::\+Conjugate\+Gradient}}$<$ Matrix\+Type\+\_\+, Up\+Lo\+\_\+, Preconditioner\+\_\+ $>$\+::\mbox{\hyperlink{class_eigen_1_1_conjugate_gradient}{Conjugate\+Gradient}} (\begin{DoxyParamCaption}\item[{const \mbox{\hyperlink{struct_eigen_1_1_eigen_base}{Eigen\+Base}}$<$ Matrix\+Derived $>$ \&}]{A }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}, {\ttfamily [explicit]}}

Initialize the solver with matrix {\itshape A} for further {\ttfamily Ax=b} solving.

This constructor is a shortcut for the default constructor followed by a call to compute().

\begin{DoxyWarning}{Warning}
this class stores a reference to the matrix A as well as some precomputed values that depend on it. Therefore, if {\itshape A} is changed this class becomes invalid. Call compute() to update it with the new matrix A, or modify a copy of A. 
\end{DoxyWarning}
\mbox{\Hypertarget{class_eigen_1_1_conjugate_gradient_aa1082311045904603fdbc9e717d40d24}\label{class_eigen_1_1_conjugate_gradient_aa1082311045904603fdbc9e717d40d24}} 
\index{Eigen::ConjugateGradient$<$ MatrixType\_, UpLo\_, Preconditioner\_ $>$@{Eigen::ConjugateGradient$<$ MatrixType\_, UpLo\_, Preconditioner\_ $>$}!ConjugateGradient@{ConjugateGradient}}
\index{ConjugateGradient@{ConjugateGradient}!Eigen::ConjugateGradient$<$ MatrixType\_, UpLo\_, Preconditioner\_ $>$@{Eigen::ConjugateGradient$<$ MatrixType\_, UpLo\_, Preconditioner\_ $>$}}
\doxysubsubsection{\texorpdfstring{ConjugateGradient()}{ConjugateGradient()}\hspace{0.1cm}{\footnotesize\ttfamily [3/4]}}
{\footnotesize\ttfamily template$<$typename Matrix\+Type\+\_\+ , int Up\+Lo\+\_\+, typename Preconditioner\+\_\+ $>$ \\
\mbox{\hyperlink{class_eigen_1_1_conjugate_gradient}{Eigen\+::\+Conjugate\+Gradient}}$<$ Matrix\+Type\+\_\+, Up\+Lo\+\_\+, Preconditioner\+\_\+ $>$\+::\mbox{\hyperlink{class_eigen_1_1_conjugate_gradient}{Conjugate\+Gradient}} (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}}

Default constructor. \mbox{\Hypertarget{class_eigen_1_1_conjugate_gradient_a81b93cc6401f61e0ff2ff0fc8a959fe3}\label{class_eigen_1_1_conjugate_gradient_a81b93cc6401f61e0ff2ff0fc8a959fe3}} 
\index{Eigen::ConjugateGradient$<$ MatrixType\_, UpLo\_, Preconditioner\_ $>$@{Eigen::ConjugateGradient$<$ MatrixType\_, UpLo\_, Preconditioner\_ $>$}!ConjugateGradient@{ConjugateGradient}}
\index{ConjugateGradient@{ConjugateGradient}!Eigen::ConjugateGradient$<$ MatrixType\_, UpLo\_, Preconditioner\_ $>$@{Eigen::ConjugateGradient$<$ MatrixType\_, UpLo\_, Preconditioner\_ $>$}}
\doxysubsubsection{\texorpdfstring{ConjugateGradient()}{ConjugateGradient()}\hspace{0.1cm}{\footnotesize\ttfamily [4/4]}}
{\footnotesize\ttfamily template$<$typename Matrix\+Type\+\_\+ , int Up\+Lo\+\_\+, typename Preconditioner\+\_\+ $>$ \\
template$<$typename Matrix\+Derived $>$ \\
\mbox{\hyperlink{class_eigen_1_1_conjugate_gradient}{Eigen\+::\+Conjugate\+Gradient}}$<$ Matrix\+Type\+\_\+, Up\+Lo\+\_\+, Preconditioner\+\_\+ $>$\+::\mbox{\hyperlink{class_eigen_1_1_conjugate_gradient}{Conjugate\+Gradient}} (\begin{DoxyParamCaption}\item[{const \mbox{\hyperlink{struct_eigen_1_1_eigen_base}{Eigen\+Base}}$<$ Matrix\+Derived $>$ \&}]{A }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}, {\ttfamily [explicit]}}

Initialize the solver with matrix {\itshape A} for further {\ttfamily Ax=b} solving.

This constructor is a shortcut for the default constructor followed by a call to compute().

\begin{DoxyWarning}{Warning}
this class stores a reference to the matrix A as well as some precomputed values that depend on it. Therefore, if {\itshape A} is changed this class becomes invalid. Call compute() to update it with the new matrix A, or modify a copy of A. 
\end{DoxyWarning}


The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
C\+:/\+Users/fab/src/\+Github/branches/\+Neural\+Amp\+Modeler\+Plugin/eigen/\+Eigen/src/\+Iterative\+Linear\+Solvers/Conjugate\+Gradient.\+h\end{DoxyCompactItemize}
